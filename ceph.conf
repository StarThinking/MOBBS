;
; Sample ceph ceph.conf file.
;
; This file defines cluster membership, the various locations
; that Ceph stores data, and any other runtime options.

; If a 'host' is defined for a daemon, the init.d start/stop script will
; verify that it matches the hostname (or else ignore it).  If it is
; not defined, it is assumed that the daemon is intended to start on
; the current host (e.g., in a setup with a startup.conf on each
; node).

; The variables $type, $id and $name are available to use in paths
; $type = The type of daemon, possible values: mon, mds and osd
; $id = The ID of the daemon, for mon.alpha, $id will be alpha
; $name = $type.$id

; For example:
; osd.0
;  $type = osd
;  $id = 0
;  $name = osd.0

; mon.beta
;  $type = mon
;  $id = beta
;  $name = mon.beta

[client]
	rbd cache = false
	rbd cache max dirty = 0
;	rbd cache writethrough until flush = true

; global
[global]
	; enable secure authentication
	auth supported = none

        ; allow ourselves to open a lot of files
        max open files = 131072

        ; set log file
        log file = /var/log/ceph/$name.log
        ;log_to_syslog = true        ; uncomment this line to log to syslog

        ; set up pid files
        pid file = /var/run/ceph/$name.pid

        ; If you want to run a IPv6 cluster, set this to true. Dual-stack isn't possible
        ;ms bind ipv6 = true

	;debug ms = 20/20

; monitors
;  You need at least one.  You need at least three if you want to
;  tolerate any node failures.  Always create an odd number.
[mon]
;        mon data = /data/$name

        ; If you are using for example the RADOS Gateway and want to have your newly created
        ; pools a higher replication level, you can set a default
        ;osd pool default size = 3

        ; You can also specify a CRUSH rule for new pools
        ; Wiki: http://ceph.newdream.net/wiki/Custom_data_placement_with_CRUSH
        ;osd pool default crush rule = 0

        ; Timing is critical for monitors, but if you want to allow the clocks to drift a
        ; bit more, you can specify the max drift.
        ;mon clock drift allowed = 1

        ; Tell the monitor to backoff from this warning for 30 seconds
        ;mon clock drift warn backoff = 30

	; logging, for debugging monitor crashes, in order of
	; their likelihood of being helpful :)
	;debug ms = 1
	;debug mon = 20
	;debug paxos = 20
	;debug auth = 20

[mon.0]
	host = MONITOR
	mon addr = 10.0.0.22:6789

; osd
;  You need at least one.  Two if you want data to be replicated.
;  Define as many as you like.
[osd]
	; This is where the osd expects its data
;	osd data = /data/$name

	; Ideally, make the journal a separate disk or partition.
 	; 1-10GB should be enough; more if you have fast or many
 	; disks.  You can use a file under the osd data dir if need be
 	; (e.g. /data/$name/journal), but it will be slower than a
 	; separate disk or partition.
        ; This is an example of a file-based journal.
;	osd journal = /data/$name/journal
	osd journal = /srv/ceph/journals/osd$id/journal
	osd journal size = 1000 ; journal size, in megabytes

        ; If you want to run the journal on a tmpfs (don't), disable DirectIO
        ;journal dio = false

        ; You can change the number of recovery operations to speed up recovery
        ; or slow it down if your machines can't handle it
        ; osd recovery max active = 3

	; osd logging to debug osd issues, in order of likelihood of being
	; helpful
	;debug ms = 1
	;debug osd = 20
	;debug filestore = 20
	;debug journal = 20


	; ### The below options only apply if you're using mkcephfs
	; ### and the devs options
        ; The filesystem used on the volumes
 ;       osd mkfs type = xfs
        ; If you want to specify some other mount options, you can do so.
        ; for other filesystems use 'osd mount options $fstype'
;	osd mount options xfs = rw,noatime
	; The options used to format the filesystem via mkfs.$fstype
        ; for other filesystems use 'osd mkfs options $fstype'

; osd mkfs options btrfs =
;filestore_queue_max_ops=500
;filestore_queue_committing_max_ops=5000
;journal_max_write_entries=1000
;journal_queue_max_ops=3000
;objecter_inflight_ops=10240
;filestore_queue_max_bytes=1048576000
;filestore_queue_committing_max_bytes=1048576000
;journal_max_write_bytes=1048576000
;journal_queue_max_bytes=1048576000
;ms_dispatch_throttle_bytes=1048576000
;objecter_infilght_op_bytes=1048576000

[osd.0]
	host = OSD-SERVER0

[osd.6]
	host = OSD-SERVER0

[osd.1]
	host = OSD-SERVER1

[osd.7]
	host = OSD-SERVER1

[osd.2]
	host = OSD-SERVER2

[osd.8]
	host = OSD-SERVER2

[osd.3]
	host = OSD-SERVER3

[osd.9]
	host = OSD-SERVER3

[osd.4]
	host = OSD-SERVER4

[osd.10]
	host = OSD-SERVER4

[osd.5]
	host = OSD-SERVER5

[osd.11]
	host = OSD-SERVER5

